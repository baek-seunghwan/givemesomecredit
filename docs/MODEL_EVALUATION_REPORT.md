# 🎓 모델 학습 및 평가 보고서

## 📊 프로젝트 개요

### 데이터셋
- **원본**: Give Me Some Credit Dataset
- **총 샘플**: 150,000개
- **최종 특성**: 5개 (상수 특성 제거 후)
- **타겟 변수**: loan (이진 분류)

### 데이터 분할
- **Training**: 53,362개 (70%)
- **Test**: 22,805개 (30%)

---

## 🔬 탐색적 데이터 분석 (EDA)

### 주요 발견사항

#### 1. 상수 특성 식별
| 특성 | 상태 | 조치 |
|------|------|------|
| gg | 모든 값 = 0 | 제거 ✓ |
| 3059 | 모든 값 = 0 | 제거 ✓ |
| Defaul | 모든 값 = 0 | 제거 ✓ |

#### 2. 타겟과의 상관계수 (특성 중요도)
| 특성 | 상관계수 | 강도 |
|------|---------|------|
| ratio (신용카드 사용률) | +0.3560 | 중간 |
| income (월 소득) | +0.2452 | 약함 |
| prop (부동산 비율) | -0.1433 | 약함 |
| depen (부양가족 수) | +0.1154 | 약함 |
| age (나이) | +0.0976 | 약함 |

#### 3. 다중공선성
- 특성 간 상관계수가 모두 0.26 이하
- **결론**: 다중공선성 없음 ✓

#### 4. 클래스 불균형
```
Training Data:
  - Class 0 (No Loan): 13,661개 (25.60%)
  - Class 1 (Has Loan): 39,701개 (74.40%)
  - 비율: 2.91:1

Test Data:
  - Class 0 (No Loan): 5,847개 (25.64%)
  - Class 1 (Has Loan): 16,958개 (74.36%)
  - 비율: 2.90:1
```

---

## ⚙️ 특성 공학

### 수행된 작업

#### 1단계: 상수 특성 제거
```
원본 특성: 9개
  ↓
제거할 특성: gg, 3059, Defaul (3개)
  ↓
최종 특성: 6개 (5개 입력 + 1개 타겟)
```

#### 2단계: 특성 선택
**최종 사용 특성**:
1. prop (부동산 담보 비율)
2. age (나이)
3. ratio (신용카드 사용률)
4. income (월 소득)
5. depen (부양가족 수)
6. **loan** (타겟 변수)

#### 3단계: 정규화 확인
- 모든 특성: [0, 1] 범위 정규화 완료 ✓

---

## 🤖 모델 개발

### 클래스 불균형 처리
```
클래스 가중치 계산:
  Class 0 가중치: 1.9531 (소수 클래스에 높은 가중치)
  Class 1 가중치: 0.6720 (다수 클래스에 낮은 가중치)
```

### 훈련된 모델

#### 1. Logistic Regression
```python
LogisticRegression(
    max_iter=1000,
    class_weight='calculated',
    random_state=42
)
```

#### 2. Random Forest
```python
RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    min_samples_split=10,
    class_weight='calculated',
    random_state=42
)
```

#### 3. XGBoost (✓ 최고 성능)
```python
XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight='calculated'
)
```

---

## 📈 모델 성능 비교

### 메트릭 비교

| 모델 | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.7708 | 0.9161 | 0.7615 | 0.8317 | 0.8511 |
| Random Forest | 0.8289 | 0.9036 | 0.8619 | 0.8822 | 0.8844 |
| **XGBoost** ⭐ | **0.8316** | **0.8266** | **0.9789** | **0.8963** | **0.8890** |

### 메트릭 해석

**Accuracy (정확도)**: 전체 예측 중 맞춘 비율
- XGBoost: 83.16% - 우수함 ✓

**Precision (정밀도)**: 양성으로 예측한 중 실제 양성 비율
- Logistic Regression: 91.61% (가장 높음)
- XGBoost: 82.66% (중간)

**Recall (재현율)**: 실제 양성 중 맞게 예측한 비율
- XGBoost: 97.89% (거의 모든 양성 탐지) ✓
- 신용 리스크 식별에 중요함

**F1-Score**: Precision과 Recall의 조화평균
- XGBoost: 0.8963 (최고) ✓

**ROC-AUC**: 모든 임계값에서의 성능
- XGBoost: 0.8890 (최고) ✓

---

## 🏆 최고 성능 모델: XGBoost

### 성능 지표
```
Accuracy:  83.16%
Precision: 82.66%
Recall:    97.89%
F1-Score:  0.8963
ROC-AUC:   0.8890
```

### 혼동 행렬 (Confusion Matrix)

```
                예측
실제        Negative  Positive
---------  ---------  ---------
Negative   2,365(TN)  3,482(FP)
Positive   358(FN)    16,600(TP)
```

### 해석

- **True Positives (TP)**: 16,600
  - 실제 대출자 중 올바르게 식별
  
- **True Negatives (TN)**: 2,365
  - 실제 비대출자 중 올바르게 식별
  
- **False Positives (FP)**: 3,482
  - 비대출자를 대출자로 잘못 식별 (위험)
  
- **False Negatives (FN)**: 358
  - 대출자를 비대출자로 놓침 (매우 적음) ✓

### 추가 메트릭

| 메트릭 | 값 | 해석 |
|--------|-----|------|
| Sensitivity (Recall) | 0.9789 | 실제 대출자의 97.89% 탐지 ✓ |
| Specificity | 0.4045 | 비대출자의 40.45만 정확히 탐지 |
| False Positive Rate | 0.5955 | 비대출자 중 59.55% 오분류 |
| False Negative Rate | 0.0211 | 대출자 중 2.11%만 놓침 ✓ |

---

## 💡 모델 선택 이유

### XGBoost를 선택한 이유:

1. **최고의 F1-Score** (0.8963)
   - Precision과 Recall의 최적 균형
   
2. **최고의 ROC-AUC** (0.8890)
   - 모든 임계값에서 우수한 성능
   
3. **뛰어난 Recall** (97.89%)
   - 신용 리스크를 거의 놓치지 않음
   - 금융 기관에 중요한 지표
   
4. **안정적인 Accuracy** (83.16%)
   - Random Forest와 비슷하지만 Recall이 더 높음

---

## ⚠️ 주의사항

### False Positives가 높은 이유
- XGBoost는 Recall을 최대화하도록 최적화됨
- 비대출자 중 59.55%를 대출자로 오분류
- **트레이드오프**: 신용 리스크 놓침을 피하기 위해 일부 보수적인 예측

### 개선 방안
1. **임계값 조정**: 기본값 0.5에서 조정 가능
2. **Precision 개선**: False Positive 감소 목표
3. **모델 앙상블**: 여러 모델 조합
4. **추가 특성**: 새로운 특성 공학

---

## 📊 최종 결과 요약

### 🎯 목표 달성
| 목표 | 결과 | 상태 |
|------|------|------|
| 모델 정확도 80% 이상 | 83.16% | ✓ |
| Recall 90% 이상 | 97.89% | ✓ |
| ROC-AUC 0.85 이상 | 0.8890 | ✓ |

### 📈 모델 성능 평가
```
우수: XGBoost
      ├─ Accuracy: 83.16%
      ├─ Recall: 97.89%
      ├─ F1-Score: 0.8963
      └─ ROC-AUC: 0.8890

양호: Random Forest
      ├─ Accuracy: 82.89%
      ├─ Precision: 90.36%
      └─ F1-Score: 0.8822

양호: Logistic Regression
      ├─ Accuracy: 77.08%
      ├─ Precision: 91.61%
      └─ F1-Score: 0.8317
```

---

## 🔮 실제 적용 시나리오

### 대출 승인 시스템에 적용할 경우

**시나리오**: 새로운 대출 신청자 평가

```
1. 입력 특성:
   - prop: 0.15 (부동산 담보 비율)
   - age: 0.45 (정규화된 나이)
   - ratio: 0.20 (신용카드 사용률)
   - income: 0.50 (정규화된 월 소득)
   - depen: 0.10 (부양가족 수)

2. XGBoost 예측:
   - Prediction: 1 (대출자 가능성 높음)
   - Probability: 0.92 (92% 확률)

3. 의사결정:
   - Probability > 0.5 → 대출 승인 고려
   - 추가 검토 권장 (신용조회 등)
```

---

## 🎓 결론

### 주요 성과
✅ 완전한 머신러닝 파이프라인 구축
✅ 3개 모델 비교 및 최적화
✅ 83.16% 정확도 달성
✅ 97.89% Recall로 신용 리스크 효과적 탐지
✅ 클래스 불균형 처리 완료

### 추천사항
1. **XGBoost 채택**: 최고 성능 모델
2. **임계값 튜닝**: 비즈니스 요구사항에 맞게 조정
3. **정기 모니터링**: 모델 성능 추적
4. **추가 데이터**: 새로운 특성 및 데이터 추가 검토

---

**작성일**: 2025년 11월 11일
**상태**: 완료 ✨

---

*이 보고서는 데이터 전처리부터 모델 평가까지의 전체 머신러닝 파이프라인을 요약합니다.*
